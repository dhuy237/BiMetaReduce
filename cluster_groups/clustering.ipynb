{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from graphframes import GraphFrame\n",
    "\n",
    "from gensim import corpora\n",
    "import sys\n",
    "import re\n",
    "\n",
    "sys.path.append(\"../\")  # Add \"../\" to utils folder path\n",
    "from utils import globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME_GL = globals.DATA_PATH + 'output_2_2.txt'\n",
    "FILENAME_CORPUS = globals.DATA_PATH + 'output_1_3.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "DICTIONARY_PATH = globals.DATA_PATH + \"dictionary.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['438']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test line cleaning method\n",
    "with open(FILENAME_GL) as f:\n",
    "    content = f.readlines()\n",
    "    \n",
    "a = content[0]\n",
    "\n",
    "re.sub('[null\\t\\n\\[\\]\\\"\"]', '', a).replace(' ', '').split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[438], [1251], [119], [937], [881]]\n"
     ]
    }
   ],
   "source": [
    "GL = []\n",
    "\n",
    "with open(FILENAME_GL) as f:\n",
    "    content_vertices = f.readlines()\n",
    "\n",
    "for line in content_vertices:\n",
    "    clean_line = re.sub('[null\\t\\n\\[\\]\\\"\"]', '', line).replace(' ', '').split(',')\n",
    "    GL.append(list(map(int, clean_line))) # Convert all strings in a list to int\n",
    "    \n",
    "print(GL[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dictionary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary.load(DICTIONARY_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0, [[0, 21], [1, 4], [2, 5], [3, 18], [4, 4], [5, 4], [6, 1], [7, 10], [8, 2], [9, 2], [10, 3], [11, 1], [12, 18], [13, 2], [14, 4], [15, 14], [16, 3], [18, 1], [19, 6], [20, 5], [21, 3], [23, 5], [24, 2], [27, 1], [28, 3], [29, 3], [30, 3], [31, 1], [32, 1], [34, 2], [35, 3], [36, 1], [37, 1], [38, 5], [41, 1], [42, 4], [43, 2], [44, 3], [45, 19], [46, 4], [47, 4], [48, 5], [49, 3], [50, 4], [52, 3], [54, 2], [55, 6], [56, 5], [57, 3], [58, 8], [59, 2], [61, 4], [62, 3], [63, 1], [64, 1], [65, 3], [67, 5], [68, 6], [69, 1], [70, 5], [71, 5], [72, 2], [73, 3], [74, 5], [76, 1], [79, 2], [80, 4], [81, 1], [82, 1], [91, 7], [92, 3], [94, 3], [95, 4], [97, 4], [98, 3], [99, 14], [100, 2], [101, 1], [103, 2], [105, 2], [106, 1], [107, 1], [110, 1], [114, 2], [116, 1], [117, 1], [120, 1], [121, 2], [124, 2], [125, 3], [126, 16], [127, 2], [128, 1], [129, 8], [130, 6], [131, 8], [133, 2], [134, 1], [135, 18], [136, 6], [137, 2], [138, 1], [139, 7], [140, 2], [141, 18], [142, 4], [143, 4], [144, 7], [145, 5], [146, 4], [147, 2], [148, 8], [149, 1], [150, 3], [151, 3], [152, 9], [153, 3], [154, 4], [155, 6], [156, 12], [157, 1], [158, 2], [159, 2], [160, 6], [161, 2], [162, 3], [163, 1], [164, 1], [165, 1], [166, 1], [167, 5], [168, 2], [169, 1], [170, 1], [171, 1], [172, 3], [173, 3], [174, 2], [175, 2], [176, 3], [177, 2], [178, 3], [179, 1], [180, 5], [181, 12], [182, 2], [183, 16], [184, 4], [185, 1], [186, 3], [187, 3], [188, 5], [189, 5], [190, 5], [191, 3], [192, 3], [193, 5], [194, 4], [195, 1], [196, 6], [197, 1], [198, 6], [199, 8], [200, 5], [201, 16], [202, 1], [203, 2], [204, 5], [205, 1], [206, 3], [207, 3], [208, 2], [209, 2], [210, 2], [211, 2], [212, 1], [213, 5], [214, 3], [215, 2], [216, 8], [217, 11], [218, 9], [219, 1], [220, 16], [221, 5], [222, 1], [223, 2], [224, 2], [225, 19], [226, 15], [227, 1], [228, 12]]]'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(FILENAME_CORPUS) as f:\n",
    "    content = f.readlines()\n",
    "    \n",
    "a = content[0]\n",
    "\n",
    "re.sub('[null\\t\\n]', '', a)\n",
    "\n",
    "new_content = [x.strip() for x in content] \n",
    "content0 = re.sub('[null\\t\\n]', '', new_content[0])\n",
    "content0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0, 21], [1, 4], [2, 5], [3, 18], [4, 4], [5, 4], [6, 1], [7, 10], [8, 2], [9, 2], [10, 3], [11, 1], [12, 18], [13, 2], [14, 4], [15, 14], [16, 3], [18, 1], [19, 6], [20, 5], [21, 3], [23, 5], [24, 2], [27, 1], [28, 3], [29, 3], [30, 3], [31, 1], [32, 1], [34, 2], [35, 3], [36, 1], [37, 1], [38, 5], [41, 1], [42, 4], [43, 2], [44, 3], [45, 19], [46, 4], [47, 4], [48, 5], [49, 3], [50, 4], [52, 3], [54, 2], [55, 6], [56, 5], [57, 3], [58, 8], [59, 2], [61, 4], [62, 3], [63, 1], [64, 1], [65, 3], [67, 5], [68, 6], [69, 1], [70, 5], [71, 5], [72, 2], [73, 3], [74, 5], [76, 1], [79, 2], [80, 4], [81, 1], [82, 1], [91, 7], [92, 3], [94, 3], [95, 4], [97, 4], [98, 3], [99, 14], [100, 2], [101, 1], [103, 2], [105, 2], [106, 1], [107, 1], [110, 1], [114, 2], [116, 1], [117, 1], [120, 1], [121, 2], [124, 2], [125, 3], [126, 16], [127, 2], [128, 1], [129, 8], [130, 6], [131, 8], [133, 2], [134, 1], [135, 18], [136, 6], [137, 2], [138, 1], [139, 7], [140, 2], [141, 18], [142, 4], [143, 4], [144, 7], [145, 5], [146, 4], [147, 2], [148, 8], [149, 1], [150, 3], [151, 3], [152, 9], [153, 3], [154, 4], [155, 6], [156, 12], [157, 1], [158, 2], [159, 2], [160, 6], [161, 2], [162, 3], [163, 1], [164, 1], [165, 1], [166, 1], [167, 5], [168, 2], [169, 1], [170, 1], [171, 1], [172, 3], [173, 3], [174, 2], [175, 2], [176, 3], [177, 2], [178, 3], [179, 1], [180, 5], [181, 12], [182, 2], [183, 16], [184, 4], [185, 1], [186, 3], [187, 3], [188, 5], [189, 5], [190, 5], [191, 3], [192, 3], [193, 5], [194, 4], [195, 1], [196, 6], [197, 1], [198, 6], [199, 8], [200, 5], [201, 16], [202, 1], [203, 2], [204, 5], [205, 1], [206, 3], [207, 3], [208, 2], [209, 2], [210, 2], [211, 2], [212, 1], [213, 5], [214, 3], [215, 2], [216, 8], [217, 11], [218, 9], [219, 1], [220, 16], [221, 5], [222, 1], [223, 2], [224, 2], [225, 19], [226, 15], [227, 1], [228, 12]'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use re.sub. Just match all the chars upto \"[[\" then replace the matched chars with \"[\".\n",
    "# And remove last 2 character of the string (\"]]\")\n",
    "re.sub(r'^.*?\\[\\[', '[', content0)[:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dist(dist, groups, seeds, only_seed=True):\n",
    "    res = []\n",
    "    if only_seed:\n",
    "        print(seeds)\n",
    "        for seednodes in seeds:\n",
    "            tmp = dist[seednodes, :]\n",
    "            print(tmp)\n",
    "            if globals.GROUP_AGGREGATION == \"MEAN\":\n",
    "                res += [np.mean(tmp, axis=0)]\n",
    "            elif globals.GROUP_AGGREGATION == \"MEDIAN\":\n",
    "                res += [np.median(tmp, axis=0)]\n",
    "    else:\n",
    "        for groupnodes in groups:\n",
    "            tmp = dist[groupnodes, :]\n",
    "            if globals.GROUP_AGGREGATION == \"MEAN\":\n",
    "                res += [np.mean(tmp, axis=0)]\n",
    "\n",
    "            elif globals.GROUP_AGGREGATION == \"MEDIAN\":\n",
    "                res += [np.median(tmp, axis=0)]\n",
    "    print(\"------------------\")\n",
    "    print(np.array(res))\n",
    "    print(\"------------------\")\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_groups( group_dist ):\n",
    "    if SCALING:\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(group_dist)\n",
    "        print(X_scaled)\n",
    "    else:\n",
    "        X_scaled = group_dist\n",
    "\n",
    "    if CLUSTERING_METHOD == 'KMEANS':\n",
    "        # clustering by k-means\n",
    "        kmeans = KMeans( n_clusters=NUM_OF_SPECIES, init='k-means++')\n",
    "        y_grp_cl = kmeans.fit_predict( X_scaled )\n",
    "        \n",
    "    elif CLUSTERING_METHOD == 'SPECTRAL':\n",
    "        spectral = SpectralClustering(n_clusters=NUM_OF_SPECIES, eigen_solver='arpack',\n",
    "                                      affinity=\"nearest_neighbors\")\n",
    "        #spectral = SpectralClustering(n_clusters=NUM_OF_SPECIES, eigen_solver='arpack',\n",
    "        #                              affinity=\"rbf\")\n",
    "        y_grp_cl = spectral.fit_predict( X_scaled )\n",
    "    print(y_grp_cl)\n",
    "    return y_grp_cl;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run command for `compute_dist()`\n",
    "```python\n",
    "corpus_m = gensim.matutils.corpus2dense(corpus, len(dictionary.keys())).T\n",
    "kmer_group_dist = compute_dist( corpus_m, GL, SL, only_seed=False)\n",
    "z_kmer_grp_cl = cluster_groups( kmer_group_dist )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_m = gensim.matutils.corpus2dense(corpus, len(dictionary.keys())).T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
